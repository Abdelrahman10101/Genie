{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install gdown\n! gdown --id 1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr -O filename\n! pip install h5p\n! pip install torch_geometric\n! pip install torch_sparse torch_scatter torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\")+cpu.html","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:02:37.899234Z","iopub.execute_input":"2025-04-01T07:02:37.899616Z","iopub.status.idle":"2025-04-01T07:02:59.830859Z","shell.execute_reply.started":"2025-04-01T07:02:37.899587Z","shell.execute_reply":"2025-04-01T07:02:59.829676Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.17.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr\nFrom (redirected): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr&confirm=t&uuid=e0aa2817-33a7-466d-8051-59caab41a3a3\nTo: /kaggle/working/filename\n100%|█████████████████████████████████████████| 701M/701M [00:02<00:00, 237MB/s]\n\u001b[31mERROR: Could not find a version that satisfies the requirement h5p (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for h5p\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nLooking in links: https://data.pyg.org/whl/torch-2.5.1+cpu.html\nRequirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt25cpu)\nRequirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt25cpu)\nRequirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt25cpu)\nRequirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt25cpu)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom sklearn.neighbors import radius_neighbors_graph\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\n# ======================\n# 1. Memory-Efficient Graph Creation\n# ======================\ndef process_in_chunks(h5_path, chunk_size=30000, threshold=0.01):\n    \"\"\"Process HDF5 file in chunks to save memory\"\"\"\n    all_graphs = []\n    with h5py.File(h5_path, 'r') as f:\n        total_jets = f['X_jets'].shape[0]\n        \n        for start_idx in tqdm(range(0, total_jets, chunk_size), \n                          desc=\"Processing chunks\"):\n            end_idx = min(start_idx + chunk_size, total_jets)\n            \n            # Load chunk\n            X_chunk = f['X_jets'][start_idx:end_idx]\n            m0_chunk = f['m0'][start_idx:end_idx]\n            pt_chunk = f['pt'][start_idx:end_idx]\n            y_chunk = f['y'][start_idx:end_idx]\n            \n            # Process chunk\n            chunk_graphs = []\n            for i in range(X_chunk.shape[0]):\n                data = multi_channel_image_to_graph(\n                    X_chunk[i,0], X_chunk[i,1], X_chunk[i,2], threshold)\n                data.m0 = torch.tensor([m0_chunk[i]], dtype=torch.float)\n                data.pt = torch.tensor([pt_chunk[i]], dtype=torch.float)\n                data.y = torch.tensor([int(y_chunk[i])], dtype=torch.long)\n                chunk_graphs.append(data)\n            \n            all_graphs.extend(chunk_graphs)\n            \n            # Clean up memory\n            del X_chunk, m0_chunk, pt_chunk, y_chunk, chunk_graphs\n            gc.collect()\n    \n    return all_graphs\n\n# ======================\n# 2. Early Stopping Class\n# ======================\nclass EarlyStopping:\n    def __init__(self, patience=5, delta=0, path='best_model.pt'):\n        self.patience = patience\n        self.delta = delta\n        self.path = path\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n\n    def __call__(self, val_loss, model):\n        if self.best_score is None:\n            self.best_score = val_loss\n            self.save_checkpoint(model)\n        elif val_loss > self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = val_loss\n            self.save_checkpoint(model)\n            self.counter = 0\n\n    def save_checkpoint(self, model):\n        torch.save(model.state_dict(), self.path)\n\n# ======================\n# 3. Graph Construction \n# ======================\ndef multi_channel_image_to_graph(ecal, hcal, track, threshold=0.01):\n    \"\"\"Convert 3-channel jet image to graph\"\"\"\n    nodes = []\n    height, width = ecal.shape\n    \n    for i in range(height):\n        for j in range(width):\n            total_energy = ecal[i,j] + hcal[i,j] + track[i,j]\n            if total_energy > threshold:\n                nodes.append([\n                    i/float(height),   # norm x\n                    j/float(width),   # norm y\n                    ecal[i,j],        # ECAL\n                    hcal[i,j],        # HCAL\n                    track[i,j]        # Track\n                ])\n    \n    if len(nodes) == 0:  # Fallback\n        combined = ecal + hcal + track\n        max_idx = np.unravel_index(np.argmax(combined), combined.shape)\n        nodes.append([\n            max_idx[0]/float(height), max_idx[1]/float(width),\n            ecal[max_idx], hcal[max_idx], track[max_idx]\n        ])\n    \n    nodes = np.array(nodes, dtype=np.float32)\n    pos = nodes[:, :2]\n    \n    if len(nodes) > 1:\n        edges = radius_neighbors_graph(pos, radius=0.15, mode='connectivity')\n        edge_index = torch.tensor(edges.nonzero(), dtype=torch.long)\n    else:\n        edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n    \n    return Data(x=torch.tensor(nodes, dtype=torch.float),\n                edge_index=edge_index)\n\n# ======================\n# 4. GNN Model\n# ======================\nclass EdgeConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='mean')\n        self.mlp = nn.Sequential(\n            nn.Linear(2*in_channels, out_channels),\n            nn.ReLU(),\n            nn.BatchNorm1d(out_channels),\n            nn.Linear(out_channels, out_channels)\n        )\n    \n    def forward(self, x, edge_index):\n        return self.propagate(edge_index, x=x)\n    \n    def message(self, x_i, x_j):\n        return self.mlp(torch.cat([x_i, x_j-x_i], dim=1))\n\nclass JetGNN(nn.Module):\n    def __init__(self, node_features=5, hidden_dim=64):\n        super().__init__()\n        self.conv1 = EdgeConv(node_features, hidden_dim)\n        self.conv2 = EdgeConv(hidden_dim, hidden_dim)\n        self.conv3 = EdgeConv(hidden_dim, hidden_dim)\n        self.global_mlp = nn.Sequential(\n            nn.Linear(2, 12),\n            nn.ReLU(),\n            nn.BatchNorm1d(12))\n        self.classifier = nn.Sequential(\n            nn.Linear(12 + hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, 2))\n    \n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = F.leaky_relu(self.conv1(x, edge_index))\n        x = F.leaky_relu(self.conv2(x, edge_index))\n        x = F.leaky_relu(self.conv3(x, edge_index))\n        graph_feat = global_mean_pool(x, batch)\n        global_feat = self.global_mlp(torch.stack([data.m0, data.pt], dim=1))\n        return self.classifier(torch.cat([graph_feat, global_feat], dim=1))\n\n# ======================\n# 5. Data Loading (First 30,000 jets only)\n# ======================\ndef load_data(filename, num_jets=30000):\n    with h5py.File(filename, 'r') as f:\n        X_jets = f['X_jets'][:num_jets]  # Only load first 30,000 jets\n        m0 = f['m0'][:num_jets]\n        pt = f['pt'][:num_jets]\n        y = f['y'][:num_jets]\n    return X_jets, m0, pt, y\n\ndef create_graph_dataset(X_jets, m0, pt, y, threshold=0.01):\n    graphs = []\n    num_jets = X_jets.shape[0]\n    \n    for i in tqdm(range(num_jets), desc=\"Creating graphs\"):\n        ecal = X_jets[i, 0, :, :]  # ECAL channel\n        hcal = X_jets[i, 1, :, :]  # HCAL channel\n        track = X_jets[i, 2, :, :]  # Track channel\n        \n        data = multi_channel_image_to_graph(ecal, hcal, track, threshold)\n        data.m0 = torch.tensor([m0[i]], dtype=torch.float)\n        data.pt = torch.tensor([pt[i]], dtype=torch.float)\n        data.y = torch.tensor([int(y[i])], dtype=torch.long)\n        graphs.append(data)\n    \n    return graphs\n\n# ======================\n# 6. Training Loop with tqdm\n# ======================\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, correct = 0, 0\n    pbar = tqdm(loader, leave=False, desc=\"Training\")\n    for data in pbar:\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data)\n        loss = criterion(out, data.y.squeeze())\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        correct += (out.argmax(dim=1) == data.y.squeeze()).sum().item()\n        pbar.set_postfix({\n            'loss': f\"{loss.item():.4f}\",\n            'acc': f\"{(out.argmax(dim=1) == data.y.squeeze()).float().mean().item():.4f}\"\n        })\n    \n    return total_loss/len(loader), correct/len(loader.dataset)\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss, correct = 0, 0\n    all_preds = []\n    all_targets = []\n    pbar = tqdm(loader, leave=False, desc=\"Validation\")\n    with torch.no_grad():\n        for data in pbar:\n            data = data.to(device)\n            out = model(data)\n            loss = criterion(out, data.y.squeeze())\n            total_loss += loss.item()\n            correct += (out.argmax(dim=1) == data.y.squeeze()).sum().item()\n            \n            # Store predictions and targets for AUC calculation\n            probs = F.softmax(out, dim=1)\n            all_preds.append(probs[:, 1].cpu().numpy())  # Probability of class 1\n            all_targets.append(data.y.squeeze().cpu().numpy())\n            \n            pbar.set_postfix({\n                'val_loss': f\"{loss.item():.4f}\",\n                'val_acc': f\"{(out.argmax(dim=1) == data.y.squeeze()).float().mean().item():.4f}\"\n            })\n    \n    # Calculate AUC\n    all_preds = np.concatenate(all_preds)\n    all_targets = np.concatenate(all_targets)\n    auc = roc_auc_score(all_targets, all_preds)\n    \n    return total_loss/len(loader), correct/len(loader.dataset), auc\n\n# ======================\n# 7. Main Execution\n# ======================\ndef main():\n    # Config\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    threshold = 0.01\n    patience = 5\n    lr = 0.001\n    batch_size = 32\n    hidden_dim = 128\n    chunk_size = 30000  # Process 30,000 jets at a time\n    \n    # Process data in chunks\n    print(\"Processing entire dataset in chunks...\")\n    graphs = process_in_chunks('/kaggle/working/filename', chunk_size, threshold)\n    \n    # Split data\n    train_graphs, val_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n    del graphs  # Free memory\n    gc.collect()\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_graphs, batch_size=batch_size)\n    \n    # Initialize model\n    model = JetGNN(hidden_dim=hidden_dim).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n    criterion = nn.CrossEntropyLoss()\n    early_stopping = EarlyStopping(patience=patience, path='best_jetgnn.pt')\n    \n    # Training loop\n    best_auc = 0.0\n    for epoch in range(100):\n        # Training\n        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        \n        # Validation\n        val_loss, val_acc, val_auc = validate(model, val_loader, criterion, device)\n        \n        # Update scheduler\n        scheduler.step(val_loss)\n        \n        # Track best AUC\n        if val_auc > best_auc:\n            best_auc = val_auc\n            torch.save(model.state_dict(), 'best_jetgnn_auc.pt')\n        \n        # Print epoch stats\n        print(f\"\\nEpoch {epoch+1:03d}\")\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n        print(f\"Best AUC: {best_auc:.4f}\")\n        print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        \n        # Early stopping check\n        early_stopping(val_loss, model)\n        if early_stopping.early_stop:\n            print(\"\\nEarly stopping triggered\")\n            break\n    \n    # Load best model (based on validation loss)\n    model.load_state_dict(torch.load('best_jetgnn.pt'))\n    print(\"\\nTraining complete. Best model saved to 'best_jetgnn.pt'\")\n    print(f\"Best AUC during training: {best_auc:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:02:59.832491Z","iopub.execute_input":"2025-04-01T07:02:59.832801Z","iopub.status.idle":"2025-04-01T07:13:15.050701Z","shell.execute_reply.started":"2025-04-01T07:02:59.832775Z","shell.execute_reply":"2025-04-01T07:13:15.049820Z"}},"outputs":[{"name":"stdout","text":"Processing entire dataset in chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing chunks:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e1dcce0b66453883a4e2160d9039cf"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 001\nTrain Loss: 0.6201 | Train Acc: 0.6603\nVal Loss: 0.6121 | Val Acc: 0.6686 | Val AUC: 0.7283\nBest AUC: 0.7283\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 002\nTrain Loss: 0.6166 | Train Acc: 0.6648\nVal Loss: 0.6109 | Val Acc: 0.6692 | Val AUC: 0.7293\nBest AUC: 0.7293\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 003\nTrain Loss: 0.6163 | Train Acc: 0.6646\nVal Loss: 0.6132 | Val Acc: 0.6678 | Val AUC: 0.7273\nBest AUC: 0.7293\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 004\nTrain Loss: 0.6170 | Train Acc: 0.6635\nVal Loss: 0.6110 | Val Acc: 0.6706 | Val AUC: 0.7288\nBest AUC: 0.7293\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 005\nTrain Loss: 0.6159 | Train Acc: 0.6638\nVal Loss: 0.6093 | Val Acc: 0.6704 | Val AUC: 0.7296\nBest AUC: 0.7296\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 006\nTrain Loss: 0.6160 | Train Acc: 0.6644\nVal Loss: 0.6100 | Val Acc: 0.6697 | Val AUC: 0.7290\nBest AUC: 0.7296\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 007\nTrain Loss: 0.6163 | Train Acc: 0.6643\nVal Loss: 0.6103 | Val Acc: 0.6676 | Val AUC: 0.7297\nBest AUC: 0.7297\nLR: 1.00e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 008\nTrain Loss: 0.6156 | Train Acc: 0.6638\nVal Loss: 0.6097 | Val Acc: 0.6699 | Val AUC: 0.7292\nBest AUC: 0.7297\nLR: 5.00e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 009\nTrain Loss: 0.6158 | Train Acc: 0.6646\nVal Loss: 0.6096 | Val Acc: 0.6705 | Val AUC: 0.7295\nBest AUC: 0.7297\nLR: 5.00e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/3483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/871 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 010\nTrain Loss: 0.6160 | Train Acc: 0.6641\nVal Loss: 0.6096 | Val Acc: 0.6703 | Val AUC: 0.7297\nBest AUC: 0.7297\nLR: 5.00e-04\n\nEarly stopping triggered\n\nTraining complete. Best model saved to 'best_jetgnn.pt'\nBest AUC during training: 0.7297\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-39-f1e9a586ee29>:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_jetgnn.pt'))\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}