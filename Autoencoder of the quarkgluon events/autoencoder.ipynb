{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0c2ac1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-28T05:41:27.791618Z",
     "iopub.status.busy": "2025-03-28T05:41:27.791276Z",
     "iopub.status.idle": "2025-03-28T05:41:39.224195Z",
     "shell.execute_reply": "2025-03-28T05:41:39.223274Z"
    },
    "papermill": {
     "duration": 11.438254,
     "end_time": "2025-03-28T05:41:39.225901",
     "exception": false,
     "start_time": "2025-03-28T05:41:27.787647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.17.0)\r\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.1.31)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From (original): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr\r\n",
      "From (redirected): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr&confirm=t&uuid=6116801f-90c2-4cc4-8b44-5c33ba159c9f\r\n",
      "To: /kaggle/working/filename\r\n",
      "100%|█████████████████████████████████████████| 701M/701M [00:02<00:00, 265MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "! pip install gdown\n",
    "! gdown --id 1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr -O filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1444316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T05:41:39.234521Z",
     "iopub.status.busy": "2025-03-28T05:41:39.234221Z",
     "iopub.status.idle": "2025-03-28T05:41:40.247550Z",
     "shell.execute_reply": "2025-03-28T05:41:40.246468Z"
    },
    "papermill": {
     "duration": 1.019029,
     "end_time": "2025-03-28T05:41:40.249110",
     "exception": false,
     "start_time": "2025-03-28T05:41:39.230081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement h5p (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for h5p\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install h5p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42f0593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T05:41:40.257714Z",
     "iopub.status.busy": "2025-03-28T05:41:40.257455Z",
     "iopub.status.idle": "2025-03-28T05:41:40.263794Z",
     "shell.execute_reply": "2025-03-28T05:41:40.263035Z"
    },
    "papermill": {
     "duration": 0.012042,
     "end_time": "2025-03-28T05:41:40.264998",
     "exception": false,
     "start_time": "2025-03-28T05:41:40.252956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import matplotlib.pyplot as plt\n",
    "# import concurrent.futures\n",
    "\n",
    "# # ========================\n",
    "# # Configuration\n",
    "# # ========================\n",
    "# config = {\n",
    "#     'batch_size': 64,\n",
    "#     'num_epochs': 50,\n",
    "#     'initial_lr': 1e-3,\n",
    "#     'patience': 5,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'num_workers': min(8, os.cpu_count()),  # Limit to 8 workers max\n",
    "#     'pin_memory': True,\n",
    "#     'persistent_workers': True,\n",
    "#     'sparse_threshold': 1e-6,\n",
    "#     'save_full_precision': True,\n",
    "#     'precision_decimals': 8\n",
    "# }\n",
    "\n",
    "# # Set numerical precision\n",
    "# torch.set_printoptions(precision=config['precision_decimals'])\n",
    "# np.set_printoptions(precision=config['precision_decimals'])\n",
    "\n",
    "# # ========================\n",
    "# # Custom Components\n",
    "# # ========================\n",
    "# class HandleSparseImages:\n",
    "#     def __call__(self, img):\n",
    "#         sparse_mask = (img < config['sparse_threshold'])\n",
    "#         noise = torch.randn_like(img) * config['sparse_threshold'] * 0.1\n",
    "#         return torch.where(sparse_mask, img + noise, img)\n",
    "\n",
    "# class JetAutoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # Encoder\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(256, 512, 3, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(512*8*8, 8192),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         # Decoder\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(8192, 512*8*8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Unflatten(1, (512, 8, 8)),\n",
    "#             nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(64, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.decoder(self.encoder(x))\n",
    "\n",
    "# # ========================\n",
    "# # Data Loading\n",
    "# # ========================\n",
    "# def load_data():\n",
    "#     print(\"Loading data with full precision...\")\n",
    "#     with h5py.File('/kaggle/working/filename', 'r') as f:\n",
    "#         X_jets = f['X_jets'][:30000].astype(np.float32)\n",
    "    \n",
    "#     if config['save_full_precision']:\n",
    "#         np.save('X_jets_original.npy', X_jets)\n",
    "#         print(\"Saved original data with full precision\")\n",
    "    \n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((128, 128)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min())),\n",
    "#         HandleSparseImages()\n",
    "#     ])\n",
    "    \n",
    "#     def process_batch(batch):\n",
    "#         return torch.stack([transform(img) for img in batch])\n",
    "    \n",
    "#     print(\"Processing images with all workers...\")\n",
    "#     batches = np.array_split(X_jets, config['num_workers'])\n",
    "#     results = []\n",
    "    \n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=config['num_workers']) as executor:\n",
    "#         futures = [executor.submit(process_batch, batch) for batch in batches]\n",
    "#         for future in tqdm(concurrent.futures.as_completed(futures), \n",
    "#                          total=len(futures),\n",
    "#                          desc=\"Processing\"):\n",
    "#             results.append(future.result())\n",
    "    \n",
    "#     return torch.cat(results)\n",
    "\n",
    "# # ========================\n",
    "# # Training Utilities\n",
    "# # ========================\n",
    "# def save_reconstructions(loader, epoch, n=5):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         batch = next(iter(loader)).to(device)\n",
    "#         reconstructions = model(batch[:n])\n",
    "        \n",
    "#         if config['save_full_precision']:\n",
    "#             np.save(f'reconstructions_epoch_{epoch}.npy', reconstructions.cpu().numpy())\n",
    "        \n",
    "#         fig, axes = plt.subplots(2, n, figsize=(15, 6))\n",
    "#         for i in range(n):\n",
    "#             # Input image\n",
    "#             axes[0,i].imshow(batch[i].cpu().permute(1,2,0))\n",
    "#             axes[0,i].set_title(\n",
    "#                 f\"Input\\nMin: {batch[i].min().item():.{config['precision_decimals']}f}\\n\"\n",
    "#                 f\"Max: {batch[i].max().item():.{config['precision_decimals']}f}\"\n",
    "#             )\n",
    "#             # Reconstruction\n",
    "#             axes[1,i].imshow(reconstructions[i].cpu().permute(1,2,0))\n",
    "#             axes[1,i].set_title(\n",
    "#                 f\"Recon\\nMin: {reconstructions[i].min().item():.{config['precision_decimals']}f}\\n\"\n",
    "#                 f\"Max: {reconstructions[i].max().item():.{config['precision_decimals']}f}\"\n",
    "#             )\n",
    "#             axes[0,i].axis('off')\n",
    "#             axes[1,i].axis('off')\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'reconstructions_epoch_{epoch}.png', dpi=300, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         #print(f\"Saved reconstructions for epoch {epoch}\")\n",
    "\n",
    "# # ========================\n",
    "# # Main Training Loop\n",
    "# # ========================\n",
    "# def main():\n",
    "#     global device, model\n",
    "    \n",
    "#     # Initialize\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Load data\n",
    "#     X_jets = load_data()\n",
    "    \n",
    "#     # Create datasets\n",
    "#     train_size = int(0.8 * len(X_jets))\n",
    "#     val_size = int(0.1 * len(X_jets))\n",
    "#     test_size = len(X_jets) - train_size - val_size\n",
    "    \n",
    "#     train_data, val_data, test_data = torch.utils.data.random_split(\n",
    "#         X_jets, [train_size, val_size, test_size])\n",
    "    \n",
    "#     # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=config['batch_size'], \n",
    "#                             shuffle=True, num_workers=config['num_workers'],\n",
    "#                             pin_memory=config['pin_memory'],\n",
    "#                             persistent_workers=config['persistent_workers'])\n",
    "    \n",
    "#     val_loader = DataLoader(val_data, batch_size=config['batch_size'],\n",
    "#                           num_workers=config['num_workers'],\n",
    "#                           pin_memory=config['pin_memory'],\n",
    "#                           persistent_workers=config['persistent_workers'])\n",
    "    \n",
    "#     test_loader = DataLoader(test_data, batch_size=config['batch_size'],\n",
    "#                            num_workers=config['num_workers'],\n",
    "#                            pin_memory=config['pin_memory'])\n",
    "    \n",
    "#     # Initialize model\n",
    "#     model = JetAutoencoder().to(device)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config['initial_lr'])\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, 'min', \n",
    "#                                 patience=config['patience'],\n",
    "#                                 min_lr=config['min_lr'],\n",
    "#                                 verbose=True)\n",
    "#     writer = SummaryWriter()\n",
    "    \n",
    "#     # Training\n",
    "#     best_loss = float('inf')\n",
    "#     early_stop_counter = 0\n",
    "    \n",
    "#     for epoch in range(config['num_epochs']):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         train_pbar = tqdm(train_loader, \n",
    "#                          desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Train]')\n",
    "        \n",
    "#         for batch in train_pbar:\n",
    "#             batch = batch.to(device, non_blocking=True)\n",
    "#             optimizer.zero_grad(set_to_none=True)\n",
    "#             outputs = model(batch)\n",
    "#             loss = criterion(outputs, batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             train_loss += loss.item()\n",
    "#             train_pbar.set_postfix({\n",
    "#                 'loss': format(loss.item(), f\".{config['precision_decimals']}f\"),\n",
    "#                 'min': format(batch.min().item(), f\".{config['precision_decimals']}f\"),\n",
    "#                 'max': format(batch.max().item(), f\".{config['precision_decimals']}f\"),\n",
    "#                 'sparse%': f\"{(batch < config['sparse_threshold']).float().mean().item() * 100:.2f}\"\n",
    "#             })\n",
    "        \n",
    "#         train_loss /= len(train_loader)\n",
    "        \n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         val_pbar = tqdm(val_loader,\n",
    "#                        desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Val]')\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_pbar:\n",
    "#                 batch = batch.to(device, non_blocking=True)\n",
    "#                 outputs = model(batch)\n",
    "#                 loss = criterion(outputs, batch)\n",
    "#                 val_loss += loss.item()\n",
    "#                 val_pbar.set_postfix({\n",
    "#                     'val_loss': format(loss.item(), f\".{config['precision_decimals']}f\")\n",
    "#                 })\n",
    "        \n",
    "#         val_loss /= len(val_loader)\n",
    "#         scheduler.step(val_loss)\n",
    "        \n",
    "#         # Logging\n",
    "#         writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "#         writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "#         writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "#         print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "#         print(f\"Train Loss: {train_loss:.{config['precision_decimals']}f}\")\n",
    "#         print(f\"Val Loss: {val_loss:.{config['precision_decimals']}f}\")\n",
    "#         #print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "#         # Save best model\n",
    "#         if val_loss < best_loss:\n",
    "#             best_loss = val_loss\n",
    "#             early_stop_counter = 0\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#             save_reconstructions(test_loader, epoch)\n",
    "#             #print(\"Saved best model and reconstructions\")\n",
    "#         else:\n",
    "#             early_stop_counter += 1\n",
    "#             if early_stop_counter >= config['patience']:\n",
    "#                 print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "#                 break\n",
    "    \n",
    "#     # Final save\n",
    "#     torch.save(model.state_dict(), 'final_model.pth')\n",
    "#     writer.close()\n",
    "#     print(\"Training complete!\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c06284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T05:41:40.272523Z",
     "iopub.status.busy": "2025-03-28T05:41:40.272269Z",
     "iopub.status.idle": "2025-03-28T05:41:43.396636Z",
     "shell.execute_reply": "2025-03-28T05:41:43.395941Z"
    },
    "papermill": {
     "duration": 3.12974,
     "end_time": "2025-03-28T05:41:43.398193",
     "exception": false,
     "start_time": "2025-03-28T05:41:40.268453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedMSE(nn.Module):\n",
    "    def __init__(self, weight_nonzero=1000.0):\n",
    "        super().__init__()\n",
    "        self.weight_nonzero = weight_nonzero  # Higher weight for non-zero pixels\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Create weight tensor: 1.0 for zeros, `weight_nonzero` for non-zeros\n",
    "        weights = torch.where(y_true == 0, \n",
    "                            torch.tensor(1.0, device=y_true.device),\n",
    "                            torch.tensor(self.weight_nonzero, device=y_true.device))\n",
    "        \n",
    "        # Calculate weighted MSE\n",
    "        squared_error = (y_true - y_pred) ** 2\n",
    "        weighted_loss = weights * squared_error\n",
    "        return torch.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0732a41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T05:41:43.406827Z",
     "iopub.status.busy": "2025-03-28T05:41:43.406500Z",
     "iopub.status.idle": "2025-03-28T06:42:41.037217Z",
     "shell.execute_reply": "2025-03-28T06:42:41.036101Z"
    },
    "papermill": {
     "duration": 3657.636994,
     "end_time": "2025-03-28T06:42:41.039040",
     "exception": false,
     "start_time": "2025-03-28T05:41:43.402046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data with full precision...\n",
      "Saved original data with full precision\n",
      "Processing images with all workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 4/4 [00:36<00:00,  9.13s/it]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/80 [Train]: 100%|██████████| 375/375 [00:40<00:00,  9.20it/s, loss=0.43263274, min=-0.00000050, max=1.00000000, sparse%=99.62]\n",
      "Epoch 1/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 24.54it/s, val_loss=0.41845477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "Train Loss: 7.65912942\n",
      "Val Loss: 0.42464109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.20731798, min=-0.00000053, max=1.00000000, sparse%=99.60]\n",
      "Epoch 2/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.79it/s, val_loss=0.19521266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "Train Loss: 0.27903892\n",
      "Val Loss: 0.20257769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.14251128, min=-0.00000050, max=1.00000000, sparse%=99.62]\n",
      "Epoch 3/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.79it/s, val_loss=0.14524826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "Train Loss: 0.17227825\n",
      "Val Loss: 0.15329524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.12395865, min=-0.00000056, max=1.00000000, sparse%=99.62]\n",
      "Epoch 4/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.81it/s, val_loss=0.12350425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "Train Loss: 0.14055894\n",
      "Val Loss: 0.13254130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.12299993, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 5/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.66it/s, val_loss=0.11238321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "Train Loss: 0.12534976\n",
      "Val Loss: 0.12193083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.11316228, min=-0.00000049, max=1.00000000, sparse%=99.63]\n",
      "Epoch 6/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.68it/s, val_loss=0.10406522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "Train Loss: 0.11616644\n",
      "Val Loss: 0.11326648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.10247079, min=-0.00000050, max=1.00000000, sparse%=99.61]\n",
      "Epoch 7/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.02it/s, val_loss=0.09628642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary:\n",
      "Train Loss: 0.10630202\n",
      "Val Loss: 0.10377601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.09754950, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 8/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.68it/s, val_loss=0.08913642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Summary:\n",
      "Train Loss: 0.09788330\n",
      "Val Loss: 0.09564403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.55it/s, loss=0.09198841, min=-0.00000051, max=1.00000000, sparse%=99.60]\n",
      "Epoch 9/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.39it/s, val_loss=0.08109320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Summary:\n",
      "Train Loss: 0.08994068\n",
      "Val Loss: 0.08732595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.53it/s, loss=0.07457746, min=-0.00000052, max=1.00000000, sparse%=99.61]\n",
      "Epoch 10/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.97it/s, val_loss=0.07440075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Summary:\n",
      "Train Loss: 0.08296011\n",
      "Val Loss: 0.08204594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.06933956, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 11/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.05it/s, val_loss=0.06945357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Summary:\n",
      "Train Loss: 0.07787134\n",
      "Val Loss: 0.07830775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.55it/s, loss=0.07750588, min=-0.00000051, max=1.00000000, sparse%=99.63]\n",
      "Epoch 12/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.00it/s, val_loss=0.06549219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Summary:\n",
      "Train Loss: 0.07386720\n",
      "Val Loss: 0.07464281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.55it/s, loss=0.07223446, min=-0.00000051, max=1.00000000, sparse%=99.61]\n",
      "Epoch 13/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.42it/s, val_loss=0.06221179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Summary:\n",
      "Train Loss: 0.07032278\n",
      "Val Loss: 0.07163200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.53it/s, loss=0.08325108, min=-0.00000046, max=1.00000000, sparse%=99.63]\n",
      "Epoch 14/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.08it/s, val_loss=0.05805128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Summary:\n",
      "Train Loss: 0.06646495\n",
      "Val Loss: 0.06869535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.57it/s, loss=0.06232066, min=-0.00000053, max=1.00000000, sparse%=99.62]\n",
      "Epoch 15/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.84it/s, val_loss=0.05255098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Summary:\n",
      "Train Loss: 0.06219684\n",
      "Val Loss: 0.06312087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.55it/s, loss=0.05963318, min=-0.00000050, max=1.00000000, sparse%=99.62]\n",
      "Epoch 16/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.21it/s, val_loss=0.04941090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Summary:\n",
      "Train Loss: 0.05782367\n",
      "Val Loss: 0.05935147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.56it/s, loss=0.05029511, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 17/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.02it/s, val_loss=0.04625842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Summary:\n",
      "Train Loss: 0.05412253\n",
      "Val Loss: 0.05605799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.57it/s, loss=0.04749992, min=-0.00000053, max=1.00000000, sparse%=99.62]\n",
      "Epoch 18/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.40it/s, val_loss=0.04443529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 Summary:\n",
      "Train Loss: 0.05084358\n",
      "Val Loss: 0.05355599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.57it/s, loss=0.04345256, min=-0.00000051, max=1.00000000, sparse%=99.64]\n",
      "Epoch 19/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.85it/s, val_loss=0.04119308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 Summary:\n",
      "Train Loss: 0.04807889\n",
      "Val Loss: 0.05181710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.58it/s, loss=0.04456163, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 20/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.23it/s, val_loss=0.03982357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 Summary:\n",
      "Train Loss: 0.04578857\n",
      "Val Loss: 0.04962003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.58it/s, loss=0.03897755, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 21/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.02it/s, val_loss=0.03913125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 Summary:\n",
      "Train Loss: 0.04366782\n",
      "Val Loss: 0.04834974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.60it/s, loss=0.03275830, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 22/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.24it/s, val_loss=0.03781446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 Summary:\n",
      "Train Loss: 0.04178511\n",
      "Val Loss: 0.04682781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.60it/s, loss=0.03832782, min=-0.00000054, max=1.00000000, sparse%=99.61]\n",
      "Epoch 23/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.20it/s, val_loss=0.03630389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 Summary:\n",
      "Train Loss: 0.04019179\n",
      "Val Loss: 0.04554635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.04507745, min=-0.00000048, max=1.00000000, sparse%=99.63]\n",
      "Epoch 24/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.05it/s, val_loss=0.03599426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 Summary:\n",
      "Train Loss: 0.03867638\n",
      "Val Loss: 0.04485730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.03442705, min=-0.00000050, max=1.00000000, sparse%=99.61]\n",
      "Epoch 25/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.01it/s, val_loss=0.03484939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 Summary:\n",
      "Train Loss: 0.03726051\n",
      "Val Loss: 0.04336283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.03763958, min=-0.00000051, max=1.00000000, sparse%=99.60]\n",
      "Epoch 26/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.09it/s, val_loss=0.03409149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 Summary:\n",
      "Train Loss: 0.03594535\n",
      "Val Loss: 0.04251878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02944101, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 27/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.43it/s, val_loss=0.03305940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 Summary:\n",
      "Train Loss: 0.03476010\n",
      "Val Loss: 0.04175533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.03696504, min=-0.00000052, max=1.00000000, sparse%=99.60]\n",
      "Epoch 28/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.59it/s, val_loss=0.03364769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 Summary:\n",
      "Train Loss: 0.03379289\n",
      "Val Loss: 0.04088028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.03235403, min=-0.00000054, max=1.00000000, sparse%=99.62]\n",
      "Epoch 29/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.08it/s, val_loss=0.03197841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 Summary:\n",
      "Train Loss: 0.03282780\n",
      "Val Loss: 0.04040102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02646958, min=-0.00000050, max=1.00000000, sparse%=99.63]\n",
      "Epoch 30/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.24it/s, val_loss=0.03235600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30 Summary:\n",
      "Train Loss: 0.03176166\n",
      "Val Loss: 0.03990581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.03465184, min=-0.00000049, max=1.00000000, sparse%=99.54]\n",
      "Epoch 31/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.83it/s, val_loss=0.03199828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31 Summary:\n",
      "Train Loss: 0.03089552\n",
      "Val Loss: 0.03938739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.03153823, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 32/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.98it/s, val_loss=0.03161990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32 Summary:\n",
      "Train Loss: 0.03003225\n",
      "Val Loss: 0.03930378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.03992684, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 33/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.52it/s, val_loss=0.03178299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33 Summary:\n",
      "Train Loss: 0.02926991\n",
      "Val Loss: 0.03866363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02933201, min=-0.00000052, max=1.00000000, sparse%=99.61]\n",
      "Epoch 34/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.25it/s, val_loss=0.03040527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34 Summary:\n",
      "Train Loss: 0.02849695\n",
      "Val Loss: 0.03798308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02855695, min=-0.00000056, max=1.00000000, sparse%=99.60]\n",
      "Epoch 35/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.93it/s, val_loss=0.03051253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35 Summary:\n",
      "Train Loss: 0.02793522\n",
      "Val Loss: 0.03764588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01940742, min=-0.00000056, max=1.00000000, sparse%=99.62]\n",
      "Epoch 36/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.12it/s, val_loss=0.02946410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36 Summary:\n",
      "Train Loss: 0.02715585\n",
      "Val Loss: 0.03711532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02410986, min=-0.00000049, max=1.00000000, sparse%=99.62]\n",
      "Epoch 37/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.75it/s, val_loss=0.02924249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37 Summary:\n",
      "Train Loss: 0.02643048\n",
      "Val Loss: 0.03687434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02349497, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 38/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.54it/s, val_loss=0.02916436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38 Summary:\n",
      "Train Loss: 0.02586003\n",
      "Val Loss: 0.03647981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02559274, min=-0.00000050, max=1.00000000, sparse%=99.59]\n",
      "Epoch 39/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.97it/s, val_loss=0.02822987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39 Summary:\n",
      "Train Loss: 0.02532289\n",
      "Val Loss: 0.03595567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02969012, min=-0.00000049, max=1.00000000, sparse%=99.61]\n",
      "Epoch 40/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.22it/s, val_loss=0.02824024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40 Summary:\n",
      "Train Loss: 0.02470807\n",
      "Val Loss: 0.03570785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.02475443, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 41/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.90it/s, val_loss=0.02788732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41 Summary:\n",
      "Train Loss: 0.02422146\n",
      "Val Loss: 0.03563900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02262462, min=-0.00000050, max=1.00000000, sparse%=99.62]\n",
      "Epoch 42/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.86it/s, val_loss=0.02762111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42 Summary:\n",
      "Train Loss: 0.02373728\n",
      "Val Loss: 0.03542028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02037694, min=-0.00000052, max=1.00000000, sparse%=99.61]\n",
      "Epoch 43/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.01it/s, val_loss=0.02797798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43 Summary:\n",
      "Train Loss: 0.02322612\n",
      "Val Loss: 0.03533832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.02487535, min=-0.00000049, max=1.00000000, sparse%=99.62]\n",
      "Epoch 44/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.75it/s, val_loss=0.02778326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44 Summary:\n",
      "Train Loss: 0.02279039\n",
      "Val Loss: 0.03484540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.02058155, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 45/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.45it/s, val_loss=0.02734186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45 Summary:\n",
      "Train Loss: 0.02226599\n",
      "Val Loss: 0.03468670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01648115, min=-0.00000050, max=1.00000000, sparse%=99.61]\n",
      "Epoch 46/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.09it/s, val_loss=0.02676333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46 Summary:\n",
      "Train Loss: 0.02178507\n",
      "Val Loss: 0.03463839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.02007120, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 47/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.80it/s, val_loss=0.02692430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47 Summary:\n",
      "Train Loss: 0.02132134\n",
      "Val Loss: 0.03427126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.01933884, min=-0.00000052, max=1.00000000, sparse%=99.63]\n",
      "Epoch 48/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.62it/s, val_loss=0.02741626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48 Summary:\n",
      "Train Loss: 0.02101629\n",
      "Val Loss: 0.03450143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01796938, min=-0.00000049, max=1.00000000, sparse%=99.63]\n",
      "Epoch 49/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.75it/s, val_loss=0.02679851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49 Summary:\n",
      "Train Loss: 0.02051767\n",
      "Val Loss: 0.03394697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01792545, min=-0.00000053, max=1.00000000, sparse%=99.62]\n",
      "Epoch 50/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.99it/s, val_loss=0.02686954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50 Summary:\n",
      "Train Loss: 0.02017955\n",
      "Val Loss: 0.03391196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01631691, min=-0.00000050, max=1.00000000, sparse%=99.65]\n",
      "Epoch 51/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.68it/s, val_loss=0.02650077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51 Summary:\n",
      "Train Loss: 0.01978131\n",
      "Val Loss: 0.03362257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.01480407, min=-0.00000051, max=1.00000000, sparse%=99.63]\n",
      "Epoch 52/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.52it/s, val_loss=0.02660024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52 Summary:\n",
      "Train Loss: 0.01943588\n",
      "Val Loss: 0.03340974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01569190, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 53/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.60it/s, val_loss=0.02648032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53 Summary:\n",
      "Train Loss: 0.01904082\n",
      "Val Loss: 0.03343929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01975393, min=-0.00000052, max=1.00000000, sparse%=99.59]\n",
      "Epoch 54/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.67it/s, val_loss=0.02608714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54 Summary:\n",
      "Train Loss: 0.01876255\n",
      "Val Loss: 0.03321752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01730135, min=-0.00000049, max=1.00000000, sparse%=99.59]\n",
      "Epoch 55/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.94it/s, val_loss=0.02573032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55 Summary:\n",
      "Train Loss: 0.01848604\n",
      "Val Loss: 0.03296694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.01957983, min=-0.00000052, max=1.00000000, sparse%=99.65]\n",
      "Epoch 56/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.10it/s, val_loss=0.02581624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56 Summary:\n",
      "Train Loss: 0.01809801\n",
      "Val Loss: 0.03302040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01728424, min=-0.00000049, max=1.00000000, sparse%=99.61]\n",
      "Epoch 57/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.03it/s, val_loss=0.02657341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57 Summary:\n",
      "Train Loss: 0.01782899\n",
      "Val Loss: 0.03342268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01667169, min=-0.00000052, max=1.00000000, sparse%=99.59]\n",
      "Epoch 58/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.18it/s, val_loss=0.02689324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58 Summary:\n",
      "Train Loss: 0.01752805\n",
      "Val Loss: 0.03360200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01816462, min=-0.00000051, max=1.00000000, sparse%=99.60]\n",
      "Epoch 59/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.61it/s, val_loss=0.02573070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59 Summary:\n",
      "Train Loss: 0.01721108\n",
      "Val Loss: 0.03257217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/80 [Train]: 100%|██████████| 375/375 [00:39<00:00,  9.61it/s, loss=0.01911487, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 60/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.24it/s, val_loss=0.02549739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60 Summary:\n",
      "Train Loss: 0.01697545\n",
      "Val Loss: 0.03245810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01809147, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 61/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.75it/s, val_loss=0.02578457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61 Summary:\n",
      "Train Loss: 0.01674812\n",
      "Val Loss: 0.03267157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01768987, min=-0.00000056, max=1.00000000, sparse%=99.62]\n",
      "Epoch 62/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.40it/s, val_loss=0.02644910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62 Summary:\n",
      "Train Loss: 0.01639234\n",
      "Val Loss: 0.03322629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01824497, min=-0.00000055, max=1.00000000, sparse%=99.62]\n",
      "Epoch 63/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.89it/s, val_loss=0.02537723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63 Summary:\n",
      "Train Loss: 0.01610381\n",
      "Val Loss: 0.03210984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01657124, min=-0.00000050, max=1.00000000, sparse%=99.61]\n",
      "Epoch 64/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.30it/s, val_loss=0.02535255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64 Summary:\n",
      "Train Loss: 0.01593844\n",
      "Val Loss: 0.03251445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01067080, min=-0.00000051, max=1.00000000, sparse%=99.63]\n",
      "Epoch 65/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.74it/s, val_loss=0.02539275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65 Summary:\n",
      "Train Loss: 0.01569638\n",
      "Val Loss: 0.03221380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01747598, min=-0.00000052, max=1.00000000, sparse%=99.61]\n",
      "Epoch 66/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.19it/s, val_loss=0.02482275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66 Summary:\n",
      "Train Loss: 0.01552777\n",
      "Val Loss: 0.03202489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01529119, min=-0.00000050, max=1.00000000, sparse%=99.62]\n",
      "Epoch 67/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.70it/s, val_loss=0.02577073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67 Summary:\n",
      "Train Loss: 0.01527531\n",
      "Val Loss: 0.03274453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01369491, min=-0.00000051, max=1.00000000, sparse%=99.65]\n",
      "Epoch 68/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.75it/s, val_loss=0.02508451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68 Summary:\n",
      "Train Loss: 0.01504182\n",
      "Val Loss: 0.03206852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01602305, min=-0.00000048, max=1.00000000, sparse%=99.62]\n",
      "Epoch 69/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.65it/s, val_loss=0.02531022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69 Summary:\n",
      "Train Loss: 0.01480862\n",
      "Val Loss: 0.03216290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01793939, min=-0.00000051, max=1.00000000, sparse%=99.62]\n",
      "Epoch 70/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.15it/s, val_loss=0.02448967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70 Summary:\n",
      "Train Loss: 0.01463228\n",
      "Val Loss: 0.03176753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01255119, min=-0.00000054, max=1.00000000, sparse%=99.62]\n",
      "Epoch 71/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.02it/s, val_loss=0.02483068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71 Summary:\n",
      "Train Loss: 0.01445062\n",
      "Val Loss: 0.03183539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01332154, min=-0.00000049, max=1.00000000, sparse%=99.62]\n",
      "Epoch 72/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.15it/s, val_loss=0.02467494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72 Summary:\n",
      "Train Loss: 0.01421005\n",
      "Val Loss: 0.03181066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01443649, min=-0.00000048, max=1.00000000, sparse%=99.62]\n",
      "Epoch 73/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.64it/s, val_loss=0.02489298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73 Summary:\n",
      "Train Loss: 0.01407096\n",
      "Val Loss: 0.03176711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.62it/s, loss=0.01373040, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 74/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.13it/s, val_loss=0.02485759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74 Summary:\n",
      "Train Loss: 0.01388758\n",
      "Val Loss: 0.03181560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01389687, min=-0.00000048, max=1.00000000, sparse%=99.62]\n",
      "Epoch 75/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.18it/s, val_loss=0.02447101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75 Summary:\n",
      "Train Loss: 0.01371770\n",
      "Val Loss: 0.03181991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01223050, min=-0.00000054, max=1.00000000, sparse%=99.61]\n",
      "Epoch 76/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.77it/s, val_loss=0.02507204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76 Summary:\n",
      "Train Loss: 0.01353282\n",
      "Val Loss: 0.03237317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.00866966, min=-0.00000052, max=1.00000000, sparse%=99.61]\n",
      "Epoch 77/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.04it/s, val_loss=0.02388395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77 Summary:\n",
      "Train Loss: 0.01272034\n",
      "Val Loss: 0.03099101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01118684, min=-0.00000049, max=1.00000000, sparse%=99.62]\n",
      "Epoch 78/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.90it/s, val_loss=0.02383455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78 Summary:\n",
      "Train Loss: 0.01212849\n",
      "Val Loss: 0.03095425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.63it/s, loss=0.01315112, min=-0.00000049, max=1.00000000, sparse%=99.61]\n",
      "Epoch 79/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 35.17it/s, val_loss=0.02384167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79 Summary:\n",
      "Train Loss: 0.01182398\n",
      "Val Loss: 0.03097383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/80 [Train]: 100%|██████████| 375/375 [00:38<00:00,  9.64it/s, loss=0.01237493, min=-0.00000052, max=1.00000000, sparse%=99.62]\n",
      "Epoch 80/80 [Val]: 100%|██████████| 47/47 [00:01<00:00, 34.74it/s, val_loss=0.02387352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80 Summary:\n",
      "Train Loss: 0.01161160\n",
      "Val Loss: 0.03099995\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "\n",
    "# ========================\n",
    "# Configuration\n",
    "# ========================\n",
    "config = {\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 80,\n",
    "    'initial_lr': 1e-3,\n",
    "    'patience': 5,\n",
    "    'min_lr': 1e-6,\n",
    "    'num_workers': min(8, os.cpu_count()),  # Limit to 8 workers max\n",
    "    'pin_memory': True,\n",
    "    'persistent_workers': True,\n",
    "    'sparse_threshold': 1e-6,\n",
    "    'save_full_precision': True,\n",
    "    'precision_decimals': 8\n",
    "}\n",
    "\n",
    "# Set numerical precision\n",
    "torch.set_printoptions(precision=config['precision_decimals'])\n",
    "np.set_printoptions(precision=config['precision_decimals'])\n",
    "\n",
    "# ========================\n",
    "# Custom Components\n",
    "# ========================\n",
    "class HandleSparseImages:\n",
    "    def __call__(self, img):\n",
    "        sparse_mask = (img < config['sparse_threshold'])\n",
    "        noise = torch.randn_like(img) * config['sparse_threshold'] * 0.1\n",
    "        return torch.where(sparse_mask, img + noise, img)\n",
    "\n",
    "class JetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*8*8, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4096, 512*8*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (512, 8, 8)),\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# ========================\n",
    "# Data Loading\n",
    "# ========================\n",
    "def load_data():\n",
    "    print(\"Loading data with full precision...\")\n",
    "    with h5py.File('/kaggle/working/filename', 'r') as f:\n",
    "        X_jets = f['X_jets'][:30000].astype(np.float32)\n",
    "    \n",
    "    if config['save_full_precision']:\n",
    "        np.save('X_jets_original.npy', X_jets)\n",
    "        print(\"Saved original data with full precision\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min())),\n",
    "        HandleSparseImages()\n",
    "    ])\n",
    "    \n",
    "    def process_batch(batch):\n",
    "        return torch.stack([transform(img) for img in batch])\n",
    "    \n",
    "    print(\"Processing images with all workers...\")\n",
    "    batches = np.array_split(X_jets, config['num_workers'])\n",
    "    results = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=config['num_workers']) as executor:\n",
    "        futures = [executor.submit(process_batch, batch) for batch in batches]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), \n",
    "                         total=len(futures),\n",
    "                         desc=\"Processing\"):\n",
    "            results.append(future.result())\n",
    "    \n",
    "    return torch.cat(results)\n",
    "\n",
    "# ========================\n",
    "# Training Utilities\n",
    "# ========================\n",
    "def save_reconstructions(loader, epoch, n=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader)).to(device)\n",
    "        reconstructions = model(batch[:n])\n",
    "        \n",
    "        if config['save_full_precision']:\n",
    "            np.save(f'reconstructions_epoch_{epoch}.npy', reconstructions.cpu().numpy())\n",
    "        \n",
    "        fig, axes = plt.subplots(2, n, figsize=(15, 6))\n",
    "        for i in range(n):\n",
    "            # Input image\n",
    "            axes[0,i].imshow(batch[i].cpu().permute(1,2,0))\n",
    "            axes[0,i].set_title(\n",
    "                f\"Input\\nMin: {batch[i].min().item():.{config['precision_decimals']}f}\\n\"\n",
    "                f\"Max: {batch[i].max().item():.{config['precision_decimals']}f}\"\n",
    "            )\n",
    "            # Reconstruction\n",
    "            axes[1,i].imshow(reconstructions[i].cpu().permute(1,2,0))\n",
    "            axes[1,i].set_title(\n",
    "                f\"Recon\\nMin: {reconstructions[i].min().item():.{config['precision_decimals']}f}\\n\"\n",
    "                f\"Max: {reconstructions[i].max().item():.{config['precision_decimals']}f}\"\n",
    "            )\n",
    "            axes[0,i].axis('off')\n",
    "            axes[1,i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'reconstructions_epoch_{epoch}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        #print(f\"Saved reconstructions for epoch {epoch}\")\n",
    "\n",
    "# ========================\n",
    "# Main Training Loop\n",
    "# ========================\n",
    "def main():\n",
    "    global device, model\n",
    "    \n",
    "    # Initialize\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    X_jets = load_data()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_size = int(0.8 * len(X_jets))\n",
    "    val_size = int(0.1 * len(X_jets))\n",
    "    test_size = len(X_jets) - train_size - val_size\n",
    "    \n",
    "    train_data, val_data, test_data = torch.utils.data.random_split(\n",
    "        X_jets, [train_size, val_size, test_size])\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_data, batch_size=config['batch_size'], \n",
    "                            shuffle=True, num_workers=config['num_workers'],\n",
    "                            pin_memory=config['pin_memory'],\n",
    "                            persistent_workers=config['persistent_workers'])\n",
    "    \n",
    "    val_loader = DataLoader(val_data, batch_size=config['batch_size'],\n",
    "                          num_workers=config['num_workers'],\n",
    "                          pin_memory=config['pin_memory'],\n",
    "                          persistent_workers=config['persistent_workers'])\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=config['batch_size'],\n",
    "                           num_workers=config['num_workers'],\n",
    "                           pin_memory=config['pin_memory'])\n",
    "    \n",
    "    # Initialize model\n",
    "    model = JetAutoencoder().to(device)\n",
    "    criterion = WeightedMSE()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['initial_lr'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', \n",
    "                                patience=config['patience'],\n",
    "                                min_lr=config['min_lr'],\n",
    "                                verbose=True)\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    # Training\n",
    "    best_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_pbar = tqdm(train_loader, \n",
    "                         desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({\n",
    "                'loss': format(loss.item(), f\".{config['precision_decimals']}f\"),\n",
    "                'min': format(batch.min().item(), f\".{config['precision_decimals']}f\"),\n",
    "                'max': format(batch.max().item(), f\".{config['precision_decimals']}f\"),\n",
    "                'sparse%': f\"{(batch < config['sparse_threshold']).float().mean().item() * 100:.2f}\"\n",
    "            })\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_pbar = tqdm(val_loader,\n",
    "                       desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]} [Val]')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                batch = batch.to(device, non_blocking=True)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, batch)\n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({\n",
    "                    'val_loss': format(loss.item(), f\".{config['precision_decimals']}f\")\n",
    "                })\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Logging\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"Train Loss: {train_loss:.{config['precision_decimals']}f}\")\n",
    "        print(f\"Val Loss: {val_loss:.{config['precision_decimals']}f}\")\n",
    "        #print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            save_reconstructions(test_loader, epoch)\n",
    "            #print(\"Saved best model and reconstructions\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= config['patience']:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Final save\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    writer.close()\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72974728",
   "metadata": {
    "papermill": {
     "duration": 3.244399,
     "end_time": "2025-03-28T06:42:47.625842",
     "exception": false,
     "start_time": "2025-03-28T06:42:44.381443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3689.15325,
   "end_time": "2025-03-28T06:42:54.364621",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-28T05:41:25.211371",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
